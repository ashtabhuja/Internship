{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "582b39e9",
   "metadata": {},
   "source": [
    "# Webscrapping Assignmnet-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0352991f",
   "metadata": {},
   "source": [
    "# 1. Scrape the details of most viewed videos on YouTube from Wikipedia. \n",
    "Url= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos \n",
    "\n",
    "You need to find following details: \n",
    "\n",
    "A)Rank\n",
    "\n",
    "B) Name\n",
    "\n",
    "C) Artist\n",
    "\n",
    "D) Upload date\n",
    "\n",
    "E) Views "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d17303df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing librarries\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e32b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to webdriver\n",
    "driver=webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "\n",
    "#Opening wikipedia webpage\n",
    "url='https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77fe6438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty list for scrapping data:\n",
    "\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_date=[]\n",
    "Views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f34781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting rank via XPATH:\n",
    "\n",
    "try:\n",
    "    rank=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[1]')\n",
    "    for i in rank:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Rank.append('NA')\n",
    "    \n",
    "#Extracting name via XPATH:\n",
    "try:\n",
    "    name=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[2]')\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Name.append('NA')\n",
    "\n",
    "#Extracting artist name via XPATH:    \n",
    "try:\n",
    "    artist=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[3]')\n",
    "    for i in artist:\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Artist.append('NA')\n",
    "\n",
    "    \n",
    "#Extracting date via XPATH:\n",
    "try:\n",
    "    date=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[5]')\n",
    "    for i in date:\n",
    "        Upload_date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Upload_date.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Upload_date.append('NA')\n",
    "\n",
    "#Extracting views via XPATH:    \n",
    "\n",
    "try:\n",
    "    views=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[4]')\n",
    "    for i in views:\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Views.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Views.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6bf1a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>13.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[17]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[18]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[19]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[22]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[28]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[29]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[30]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>5.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[36]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Roar\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[42]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[43]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[44]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Sorry\"[45]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Thinking Out Loud\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[47]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Dark Horse\"[48]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"[49]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Faded\"[51]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Shree Hanuman Chalisa\"[52]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>May 10, 2011</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Girls Like You\"[53]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lean On\"[54]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[6]   \n",
       "1    2.                                   \"Despacito\"[9]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[17]   \n",
       "3    4.                                  \"Bath Song\"[18]   \n",
       "4    5.                               \"Shape of You\"[19]   \n",
       "5    6.                              \"See You Again\"[22]   \n",
       "6    7.                          \"Wheels on the Bus\"[27]   \n",
       "7    8.                \"Phonics Song with Two Words\"[28]   \n",
       "8    9.                                \"Uptown Funk\"[29]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[30]   \n",
       "10  11.                              \"Gangnam Style\"[31]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[36]   \n",
       "12  13.                             \"Dame Tu Cosita\"[37]   \n",
       "13  14.                                     \"Axel F\"[38]   \n",
       "14  15.                                      \"Sugar\"[39]   \n",
       "15  16.                             \"Counting Stars\"[40]   \n",
       "16  17.                                       \"Roar\"[41]   \n",
       "17  18.                        \"Baa Baa Black Sheep\"[42]   \n",
       "18  19.           \"Waka Waka (This Time for Africa)\"[43]   \n",
       "19  20.                             \"Lakdi Ki Kathi\"[44]   \n",
       "20  21.                                      \"Sorry\"[45]   \n",
       "21  22.                          \"Thinking Out Loud\"[46]   \n",
       "22  23.          \"Humpty the train on a fruits ride\"[47]   \n",
       "23  24.                                 \"Dark Horse\"[48]   \n",
       "24  25.                                    \"Perfect\"[49]   \n",
       "25  26.                                 \"Let Her Go\"[50]   \n",
       "26  27.                                      \"Faded\"[51]   \n",
       "27  28.                      \"Shree Hanuman Chalisa\"[52]   \n",
       "28  29.                             \"Girls Like You\"[53]   \n",
       "29  30.                                    \"Lean On\"[54]   \n",
       "\n",
       "                                               Artist        Upload Date  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                          Luis Fonsi   January 12, 2017   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "3                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "4                                          Ed Sheeran   January 30, 2017   \n",
       "5                                         Wiz Khalifa      April 6, 2015   \n",
       "6                          Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "8                                         Mark Ronson  November 19, 2014   \n",
       "9                                         Miroshka TV  February 27, 2018   \n",
       "10                                        officialpsy      July 15, 2012   \n",
       "11                                         Get Movies   January 31, 2012   \n",
       "12                                      Ultra Records      April 5, 2018   \n",
       "13                                         Crazy Frog      June 16, 2009   \n",
       "14                                           Maroon 5   January 14, 2015   \n",
       "15                                        OneRepublic       May 31, 2013   \n",
       "16                                         Katy Perry  September 5, 2013   \n",
       "17                         Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "18                                            Shakira       June 4, 2010   \n",
       "19                                       Jingle Toons      June 14, 2018   \n",
       "20                                      Justin Bieber   October 22, 2015   \n",
       "21                                         Ed Sheeran    October 7, 2014   \n",
       "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "23                                         Katy Perry  February 20, 2014   \n",
       "24                                         Ed Sheeran   November 9, 2017   \n",
       "25                                          Passenger      July 25, 2012   \n",
       "26                                        Alan Walker   December 3, 2015   \n",
       "27                              T-Series Bhakti Sagar       May 10, 2011   \n",
       "28                                           Maroon 5       May 31, 2018   \n",
       "29                               Major Lazer Official     March 22, 2015   \n",
       "\n",
       "    Views  \n",
       "0   13.65  \n",
       "1    8.32  \n",
       "2    6.84  \n",
       "3    6.50  \n",
       "4    6.14  \n",
       "5    6.09  \n",
       "6    5.71  \n",
       "7    5.57  \n",
       "8    5.09  \n",
       "9    5.01  \n",
       "10   4.96  \n",
       "11   4.57  \n",
       "12   4.48  \n",
       "13   4.16  \n",
       "14   3.97  \n",
       "15   3.92  \n",
       "16   3.91  \n",
       "17   3.84  \n",
       "18   3.78  \n",
       "19   3.76  \n",
       "20   3.74  \n",
       "21   3.69  \n",
       "22   3.63  \n",
       "23   3.63  \n",
       "24   3.60  \n",
       "25   3.56  \n",
       "26   3.55  \n",
       "27   3.54  \n",
       "28   3.52  \n",
       "29   3.50  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFrame for scrapped data:\n",
    "Wiki=pd.DataFrame({\"Rank\":Rank,\"Name\":Name,\"Artist\":Artist,\"Upload Date\":Upload_date,\"Views\":Views})\n",
    "Wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b351453",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "\n",
    "Url = https://www.bcci.tv/.\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Series\n",
    "\n",
    "B) Place\n",
    "\n",
    "C) Date\n",
    "\n",
    "D) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c69f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5534b385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to webdriver:\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "#Connecting to BCCI webpage:\n",
    "url='https://www.bcci.tv/'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a9ef91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening fixtures webpage:\n",
    "fixtures=driver.find_element(By.XPATH,'//div[1][@class=\"imw-tabs international-tabs\"]//a[2]')\n",
    "try:\n",
    "    fixtures.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(fixtures.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "106ad942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty list for scrap data:\n",
    "Series = []\n",
    "Place = []\n",
    "Date = []\n",
    "Time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "008533df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract date via XPATH:\n",
    "try:\n",
    "    date=driver.find_elements(By.XPATH,'//div[@class=\"match-date-info\"]/div[1]')\n",
    "    for dates in date:\n",
    "        Date.append(dates.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append('NA')\n",
    "\n",
    "#Extract time via XPATH:\n",
    "try:\n",
    "    time=driver.find_elements(By.XPATH,'//div[@class=\"match-date-info\"]/div[2]')\n",
    "    for times in time:\n",
    "        Time.append(times.text)\n",
    "except NoSuchElementException:\n",
    "    Time.append('NA')\n",
    "\n",
    "#Extarct place via XPATH:\n",
    "try:\n",
    "    place=driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]/span')\n",
    "    for places in place:\n",
    "        Place.append(places.text)\n",
    "except NoSuchElementException:\n",
    "    Place.append('NA')\n",
    "    \n",
    "\n",
    "#Extract match via XPATH:\n",
    "try:\n",
    "    match=driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "    for matches in match:\n",
    "        Series.append(matches.text)\n",
    "except NoSuchElementException:\n",
    "    Series.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1db75e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 9 9 9\n"
     ]
    }
   ],
   "source": [
    "print(len(Place),len(Time),len(Series),len(Date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cdb1b2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Barsapara Cricket Stadium,</td>\n",
       "      <td>27 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Guwahati</td>\n",
       "      <td>28 NOVEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENGLAND A WOMENS TOUR OF INDIA T20 SERIES</td>\n",
       "      <td>Wankhede Stadium,</td>\n",
       "      <td>29 NOVEMBER, 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENGLAND A WOMENS TOUR OF INDIA T20 SERIES</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>1 DECEMBER, 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Wankhede Stadium,</td>\n",
       "      <td>1 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENGLAND A WOMENS TOUR OF INDIA T20 SERIES</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>3 DECEMBER, 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Shaheed Veer Narayan Singh International Crick...</td>\n",
       "      <td>3 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ENGLAND WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Raipur</td>\n",
       "      <td>6 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ENGLAND WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Wankhede Stadium,</td>\n",
       "      <td>9 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Series  \\\n",
       "0       QUADRANGULAR MENS U19 ONE DAY SERIES   \n",
       "1            AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "2  ENGLAND A WOMENS TOUR OF INDIA T20 SERIES   \n",
       "3  ENGLAND A WOMENS TOUR OF INDIA T20 SERIES   \n",
       "4            AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "5  ENGLAND A WOMENS TOUR OF INDIA T20 SERIES   \n",
       "6            AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "7        ENGLAND WOMEN TOUR OF INDIA 2023-24   \n",
       "8        ENGLAND WOMEN TOUR OF INDIA 2023-24   \n",
       "\n",
       "                                               Place               Date  \\\n",
       "0                         Barsapara Cricket Stadium,  27 NOVEMBER, 2023   \n",
       "1                                           Guwahati  28 NOVEMBER, 2023   \n",
       "2                                  Wankhede Stadium,  29 NOVEMBER, 2023   \n",
       "3                                             Mumbai   1 DECEMBER, 2023   \n",
       "4                                  Wankhede Stadium,   1 DECEMBER, 2023   \n",
       "5                                             Mumbai   3 DECEMBER, 2023   \n",
       "6  Shaheed Veer Narayan Singh International Crick...   3 DECEMBER, 2023   \n",
       "7                                             Raipur   6 DECEMBER, 2023   \n",
       "8                                  Wankhede Stadium,   9 DECEMBER, 2023   \n",
       "\n",
       "          Time  \n",
       "0  9:00 AM IST  \n",
       "1  7:00 PM IST  \n",
       "2  1:30 PM IST  \n",
       "3  1:30 PM IST  \n",
       "4  7:00 PM IST  \n",
       "5  1:30 PM IST  \n",
       "6  7:00 PM IST  \n",
       "7  7:00 PM IST  \n",
       "8  7:00 PM IST  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Frame for scrapped data:\n",
    "Cricket=pd.DataFrame({\"Series\":Series[:9],\"Place\":Place[:9],\"Date\":Date[:9],\"Time\":Time[:9]})\n",
    "Cricket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9310cd2b",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "\n",
    "Url = http://statisticstimes.com/\n",
    "\n",
    "You have to find following details: \n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) State\n",
    "\n",
    "C) GSDP(18-19)- at current prices\n",
    "\n",
    "D) GSDP(19-20)- at current prices\n",
    "\n",
    "E) Share(18-19)\n",
    "\n",
    "F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "328c7901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00d4e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to webdriver:\n",
    "driver=webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "\n",
    "#opening to webpage:\n",
    "url='http://statisticstimes.com/'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12fda9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list for scarpping data:\n",
    "Rank=[]\n",
    "States=[]\n",
    "GSDP_18_19=[]\n",
    "GSDP_19_20=[]\n",
    "Share=[]\n",
    "GDP=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b24879c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on India under ecomony section\n",
    "\n",
    "India=driver.find_element(By.XPATH,'//div[2][@class=\"dropdown\"]//div/a[3]')\n",
    "try:\n",
    "    India.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(India.get_attribute('href'))\n",
    "    \n",
    "time.sleep(2)\n",
    "\n",
    "# Clicking Indian State GDP\n",
    "State=driver.find_element(By.XPATH,'//div[@style=\"float:left;background-color:seashell;width:400px;height:800px;\"]//ul/li[1]')\n",
    "try:\n",
    "    State.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(State.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec79092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Rank via XPATH\n",
    "try:\n",
    "    rank=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[1]')\n",
    "    for i in rank:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('NA')\n",
    "\n",
    "# Extracting state name via XPATH\n",
    "try:\n",
    "    states=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[2]')\n",
    "    for i in states:\n",
    "        States.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    States.append('NA')\n",
    "\n",
    "# Extracting GDSP 18-19 via XPATH    \n",
    "try:\n",
    "    gsdp_18_19=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "    for i in gsdp_18_19:\n",
    "        GSDP_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_18_19.append('NA')\n",
    "\n",
    "# Extracting GDSP 19-20 via XPATH    \n",
    "try:\n",
    "    gsdp_19_20=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[3]')\n",
    "    for i in gsdp_19_20:\n",
    "        GSDP_19_20.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_19_20.append('NA')\n",
    "\n",
    "# Extracting share in billons via XPATH    \n",
    "try:\n",
    "    share=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "    for i in share:\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append('NA')\n",
    "\n",
    "# Extracting GDP via XPATH\n",
    "try:\n",
    "    gdp=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "    for i in gdp:\n",
    "        GDP.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef632f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)-at current prices</th>\n",
       "      <th>GSDP(19-20)-at current prices</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>972,782</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>906,672</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>165,472</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(18-19)-at current prices  \\\n",
       "0     1                Maharashtra                     2,632,792   \n",
       "1     2                 Tamil Nadu                     1,630,208   \n",
       "2     3              Uttar Pradesh                     1,584,764   \n",
       "3     4                    Gujarat                     1,502,899   \n",
       "4     5                  Karnataka                     1,493,127   \n",
       "5     6                West Bengal                     1,089,898   \n",
       "6     7                  Rajasthan                       942,586   \n",
       "7     8             Andhra Pradesh                       862,957   \n",
       "8     9                  Telangana                       861,031   \n",
       "9    10             Madhya Pradesh                       809,592   \n",
       "10   11                     Kerala                       781,653   \n",
       "11   12                      Delhi                       774,870   \n",
       "12   13                    Haryana                       734,163   \n",
       "13   14                      Bihar                       530,363   \n",
       "14   15                     Punjab                       526,376   \n",
       "15   16                     Odisha                       487,805   \n",
       "16   17                      Assam                       315,881   \n",
       "17   18               Chhattisgarh                       304,063   \n",
       "18   19                  Jharkhand                       297,204   \n",
       "19   20                Uttarakhand                       245,895   \n",
       "20   21            Jammu & Kashmir                       155,956   \n",
       "21   22           Himachal Pradesh                       153,845   \n",
       "22   23                        Goa                        73,170   \n",
       "23   24                    Tripura                        49,845   \n",
       "24   25                 Chandigarh                        42,114   \n",
       "25   26                 Puducherry                        34,433   \n",
       "26   27                  Meghalaya                        33,481   \n",
       "27   28                     Sikkim                        28,723   \n",
       "28   29                    Manipur                        27,870   \n",
       "29   30                   Nagaland                        27,283   \n",
       "30   31          Arunachal Pradesh                        24,603   \n",
       "31   32                    Mizoram                        22,287   \n",
       "32   33  Andaman & Nicobar Islands                             -   \n",
       "\n",
       "   GSDP(19-20)-at current prices Share(18-19) GDP($ billion)  \n",
       "0                              -       13.94%        399.921  \n",
       "1                      1,845,853        8.63%        247.629  \n",
       "2                      1,687,818        8.39%        240.726  \n",
       "3                              -        7.96%        228.290  \n",
       "4                      1,631,977        7.91%        226.806  \n",
       "5                      1,253,832        5.77%        165.556  \n",
       "6                      1,020,989        4.99%        143.179  \n",
       "7                        972,782        4.57%        131.083  \n",
       "8                        969,604        4.56%        130.791  \n",
       "9                        906,672        4.29%        122.977  \n",
       "10                             -        4.14%        118.733  \n",
       "11                       856,112        4.10%        117.703  \n",
       "12                       831,610        3.89%        111.519  \n",
       "13                       611,804        2.81%         80.562  \n",
       "14                       574,760        2.79%         79.957  \n",
       "15                       521,275        2.58%         74.098  \n",
       "16                             -        1.67%         47.982  \n",
       "17                       329,180        1.61%         46.187  \n",
       "18                       328,598        1.57%         45.145  \n",
       "19                             -        1.30%         37.351  \n",
       "20                             -        0.83%         23.690  \n",
       "21                       165,472        0.81%         23.369  \n",
       "22                        80,449        0.39%         11.115  \n",
       "23                        55,984        0.26%          7.571  \n",
       "24                             -        0.22%          6.397  \n",
       "25                        38,253        0.18%          5.230  \n",
       "26                        36,572        0.18%          5.086  \n",
       "27                        32,496        0.15%          4.363  \n",
       "28                        31,790        0.15%          4.233  \n",
       "29                             -        0.14%          4.144  \n",
       "30                             -        0.13%          3.737  \n",
       "31                        26,503        0.12%          3.385  \n",
       "32                             -            -              -  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFrame for scrapped data\n",
    "Statewise_GDP=pd.DataFrame({\"Rank\":Rank,\"State\":States,\"GSDP(18-19)-at current prices\":GSDP_18_19,\"GSDP(19-20)-at current prices\":GSDP_19_20,\"Share(18-19)\":Share,\"GDP($ billion)\":GDP})\n",
    "Statewise_GDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f73d9ca",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "    \n",
    "You have to find the following details:\n",
    "    \n",
    "A) Repository title\n",
    "\n",
    "B) Repository description\n",
    "\n",
    "C) Contributors count\n",
    "\n",
    "D) Language used \n",
    "\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e46a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bdd6b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting webdriver:\n",
    "driver=webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "\n",
    "#opening to webpage\n",
    "url='https://github.com/'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9590176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on trending option\n",
    "trending=driver.find_element(By.XPATH,'//ul[@aria-labelledby=\"open-source-repositories-heading\"]/li[2]/a')\n",
    "try:\n",
    "    trending.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(trending.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6f816fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty list for Scraping Data\n",
    "Title=[]\n",
    "Description=[]\n",
    "Count=[]\n",
    "Language=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1bd980dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping repositories URL\n",
    "URL=[]\n",
    "link=driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]/a')\n",
    "\n",
    "for i in link:\n",
    "    URL.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2145cdcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cdcee1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Repositority Title\n",
    "try:\n",
    "    title=driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]')\n",
    "    for i in title:\n",
    "        Title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Title.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4bb57de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46864825",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)        \n",
    "# Scraping Description        \n",
    "    try:\n",
    "        description=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/main/div/div[2]/div')\n",
    "        Description.append(description.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('NA')\n",
    "        \n",
    " # Scraping Contributor count        \n",
    "    try:\n",
    "        count=driver.find_element(By.XPATH,'//div[5][@class=\"BorderGrid-row\"]//h2//span')\n",
    "        Count.append(count.text)\n",
    "    except NoSuchElementException:\n",
    "        Count.append('NA')\n",
    "  # Scraping Language   \n",
    "    try:\n",
    "        lang=driver.find_elements(By.XPATH,\"//li[@class='d-inline']//a//span[1]\")\n",
    "        for langs in lang:\n",
    "            Language.append(langs.text)\n",
    "    except NoSuchElementException:\n",
    "        Language.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ad687ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 61\n"
     ]
    }
   ],
   "source": [
    "print(len(Description),len(Count),len(Language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17907c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A quick example of how one can \"synchronize\" a...</td>\n",
       "      <td>NA</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Build ChatGPT over your data, all with natural...</td>\n",
       "      <td>5</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-2012 Roadster Development and Diagnostic ...</td>\n",
       "      <td>NA</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Awesome deals on Black Friday: Apps, SaaS, Boo...</td>\n",
       "      <td>567</td>\n",
       "      <td>Makefile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✯ 一个可直连访问的电视/广播图标库与相关工具项目 ✯ 🔕 永久免费 直连访问 完整开源 不...</td>\n",
       "      <td>NA</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Clash Nyanpasu!\\nLicense\\nGPL-3.0 license\\n2.2...</td>\n",
       "      <td>26</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>leaked prompts of GPTs\\n2.9k stars 632 forks A...</td>\n",
       "      <td>3</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The code behind my hot tips\\n686 stars 186 for...</td>\n",
       "      <td>NA</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Focus on prompting and generating\\nLicense\\nGP...</td>\n",
       "      <td>NA</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A Collection of application ideas which can be...</td>\n",
       "      <td>68</td>\n",
       "      <td>SCSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>StarRocks, a Linux Foundation project, is a ne...</td>\n",
       "      <td>293</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C Telegram bot framework\\nLicense\\nBSD-3-Claus...</td>\n",
       "      <td>NA</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>🇨🇳 GitHub中文排行榜，各语言分设「软件 | 资料」榜单，精准定位中文好项目。各取所需...</td>\n",
       "      <td>NA</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>🔥 🔥 🔥 现代化、开源的 Linux 服务器运维管理面板。\\n1panel.cn/\\nLi...</td>\n",
       "      <td>38</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>store all agent's system prompt\\nLicense\\nMIT ...</td>\n",
       "      <td>3</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Generative Models by Stability AI\\nLicense\\nMI...</td>\n",
       "      <td>15</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A one-of-a-kind resume builder that keeps your...</td>\n",
       "      <td>NA</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12 Weeks, 24 Lessons, AI for All!\\nmicrosoft.g...</td>\n",
       "      <td>33</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A curated list of awesome C++ (or C) framework...</td>\n",
       "      <td>381</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Black Friday Deals for macOS / iOS Software &amp; ...</td>\n",
       "      <td>259</td>\n",
       "      <td>Thrift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Spring Boot\\nspring.io/projects/spring-boot\\nL...</td>\n",
       "      <td>1,039</td>\n",
       "      <td>CMake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Open-source developer platform to turn scripts...</td>\n",
       "      <td>57</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Best practices for segmentation of the corpora...</td>\n",
       "      <td>NA</td>\n",
       "      <td>Makefile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>真的没有QQ群、QQ频道、论坛。打包分发注意开源协议，保留出处，不守规矩就不要搞。\\nLic...</td>\n",
       "      <td>11</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Deliver web apps with confidence 🚀\\nangular.de...</td>\n",
       "      <td>NA</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Repository Description Contributors Count  \\\n",
       "0   A quick example of how one can \"synchronize\" a...                 NA   \n",
       "1   Build ChatGPT over your data, all with natural...                  5   \n",
       "2   2008-2012 Roadster Development and Diagnostic ...                 NA   \n",
       "3   Awesome deals on Black Friday: Apps, SaaS, Boo...                567   \n",
       "4   ✯ 一个可直连访问的电视/广播图标库与相关工具项目 ✯ 🔕 永久免费 直连访问 完整开源 不...                 NA   \n",
       "5   Clash Nyanpasu!\\nLicense\\nGPL-3.0 license\\n2.2...                 26   \n",
       "6   leaked prompts of GPTs\\n2.9k stars 632 forks A...                  3   \n",
       "7   The code behind my hot tips\\n686 stars 186 for...                 NA   \n",
       "8   Focus on prompting and generating\\nLicense\\nGP...                 NA   \n",
       "9   A Collection of application ideas which can be...                 68   \n",
       "10  StarRocks, a Linux Foundation project, is a ne...                293   \n",
       "11  C Telegram bot framework\\nLicense\\nBSD-3-Claus...                 NA   \n",
       "12  🇨🇳 GitHub中文排行榜，各语言分设「软件 | 资料」榜单，精准定位中文好项目。各取所需...                 NA   \n",
       "13  🔥 🔥 🔥 现代化、开源的 Linux 服务器运维管理面板。\\n1panel.cn/\\nLi...                 38   \n",
       "14  store all agent's system prompt\\nLicense\\nMIT ...                  3   \n",
       "15  Generative Models by Stability AI\\nLicense\\nMI...                 15   \n",
       "16  A one-of-a-kind resume builder that keeps your...                 NA   \n",
       "17  12 Weeks, 24 Lessons, AI for All!\\nmicrosoft.g...                 33   \n",
       "18  A curated list of awesome C++ (or C) framework...                381   \n",
       "19  Black Friday Deals for macOS / iOS Software & ...                259   \n",
       "20  Spring Boot\\nspring.io/projects/spring-boot\\nL...              1,039   \n",
       "21  Open-source developer platform to turn scripts...                 57   \n",
       "22  Best practices for segmentation of the corpora...                 NA   \n",
       "23  真的没有QQ群、QQ频道、论坛。打包分发注意开源协议，保留出处，不守规矩就不要搞。\\nLic...                 11   \n",
       "24  Deliver web apps with confidence 🚀\\nangular.de...                 NA   \n",
       "\n",
       "   Language Used  \n",
       "0     JavaScript  \n",
       "1           HTML  \n",
       "2         Python  \n",
       "3       Makefile  \n",
       "4     JavaScript  \n",
       "5           HTML  \n",
       "6     TypeScript  \n",
       "7           Rust  \n",
       "8     JavaScript  \n",
       "9           SCSS  \n",
       "10          HTML  \n",
       "11    TypeScript  \n",
       "12    JavaScript  \n",
       "13        Python  \n",
       "14    JavaScript  \n",
       "15          Java  \n",
       "16           C++  \n",
       "17             C  \n",
       "18        Python  \n",
       "19        Thrift  \n",
       "20         CMake  \n",
       "21             C  \n",
       "22      Makefile  \n",
       "23          Java  \n",
       "24            Go  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFrame for scrapped data:\n",
    "Github=pd.DataFrame({\"Repository Description\":Description,\"Contributors Count\":Count,\"Language Used\":Language[:25]})\n",
    "Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b23c23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language Used</th>\n",
       "      <th>Repository Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A quick example of how one can \"synchronize\" a...</td>\n",
       "      <td>NA</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>bgstaal / multipleWindow3dScene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Build ChatGPT over your data, all with natural...</td>\n",
       "      <td>5</td>\n",
       "      <td>HTML</td>\n",
       "      <td>run-llama / rags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-2012 Roadster Development and Diagnostic ...</td>\n",
       "      <td>NA</td>\n",
       "      <td>Python</td>\n",
       "      <td>teslamotors / roadster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Awesome deals on Black Friday: Apps, SaaS, Boo...</td>\n",
       "      <td>567</td>\n",
       "      <td>Makefile</td>\n",
       "      <td>trungdq88 / Awesome-Black-Friday-Cyber-Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✯ 一个可直连访问的电视/广播图标库与相关工具项目 ✯ 🔕 永久免费 直连访问 完整开源 不...</td>\n",
       "      <td>NA</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>fanmingming / live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Clash Nyanpasu!\\nLicense\\nGPL-3.0 license\\n2.2...</td>\n",
       "      <td>26</td>\n",
       "      <td>HTML</td>\n",
       "      <td>keiko233 / clash-nyanpasu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>leaked prompts of GPTs\\n2.9k stars 632 forks A...</td>\n",
       "      <td>3</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>linexjlin / GPTs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The code behind my hot tips\\n686 stars 186 for...</td>\n",
       "      <td>NA</td>\n",
       "      <td>Rust</td>\n",
       "      <td>wesbos / hot-tips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Focus on prompting and generating\\nLicense\\nGP...</td>\n",
       "      <td>NA</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>lllyasviel / Fooocus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A Collection of application ideas which can be...</td>\n",
       "      <td>68</td>\n",
       "      <td>SCSS</td>\n",
       "      <td>florinpop17 / app-ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>StarRocks, a Linux Foundation project, is a ne...</td>\n",
       "      <td>293</td>\n",
       "      <td>HTML</td>\n",
       "      <td>StarRocks / starrocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C Telegram bot framework\\nLicense\\nBSD-3-Claus...</td>\n",
       "      <td>NA</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>antirez / botlib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>🇨🇳 GitHub中文排行榜，各语言分设「软件 | 资料」榜单，精准定位中文好项目。各取所需...</td>\n",
       "      <td>NA</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>GrowingGit / GitHub-Chinese-Top-Charts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>🔥 🔥 🔥 现代化、开源的 Linux 服务器运维管理面板。\\n1panel.cn/\\nLi...</td>\n",
       "      <td>38</td>\n",
       "      <td>Python</td>\n",
       "      <td>1Panel-dev / 1Panel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>store all agent's system prompt\\nLicense\\nMIT ...</td>\n",
       "      <td>3</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>LouisShark / chatgpt_system_prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Generative Models by Stability AI\\nLicense\\nMI...</td>\n",
       "      <td>15</td>\n",
       "      <td>Java</td>\n",
       "      <td>Stability-AI / generative-models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A one-of-a-kind resume builder that keeps your...</td>\n",
       "      <td>NA</td>\n",
       "      <td>C++</td>\n",
       "      <td>AmruthPillai / Reactive-Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12 Weeks, 24 Lessons, AI for All!\\nmicrosoft.g...</td>\n",
       "      <td>33</td>\n",
       "      <td>C</td>\n",
       "      <td>microsoft / AI-For-Beginners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A curated list of awesome C++ (or C) framework...</td>\n",
       "      <td>381</td>\n",
       "      <td>Python</td>\n",
       "      <td>fffaraz / awesome-cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Black Friday Deals for macOS / iOS Software &amp; ...</td>\n",
       "      <td>259</td>\n",
       "      <td>Thrift</td>\n",
       "      <td>mRs- / Black-Friday-Deals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Spring Boot\\nspring.io/projects/spring-boot\\nL...</td>\n",
       "      <td>1,039</td>\n",
       "      <td>CMake</td>\n",
       "      <td>spring-projects / spring-boot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Open-source developer platform to turn scripts...</td>\n",
       "      <td>57</td>\n",
       "      <td>C</td>\n",
       "      <td>windmill-labs / windmill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Best practices for segmentation of the corpora...</td>\n",
       "      <td>NA</td>\n",
       "      <td>Makefile</td>\n",
       "      <td>sergiomarotco / Network-segmentation-cheat-sheet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>真的没有QQ群、QQ频道、论坛。打包分发注意开源协议，保留出处，不守规矩就不要搞。\\nLic...</td>\n",
       "      <td>11</td>\n",
       "      <td>Java</td>\n",
       "      <td>CatVodTVOfficial / TVBoxOSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Deliver web apps with confidence 🚀\\nangular.de...</td>\n",
       "      <td>NA</td>\n",
       "      <td>Go</td>\n",
       "      <td>angular / angular</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Repository Description Contributors Count  \\\n",
       "0   A quick example of how one can \"synchronize\" a...                 NA   \n",
       "1   Build ChatGPT over your data, all with natural...                  5   \n",
       "2   2008-2012 Roadster Development and Diagnostic ...                 NA   \n",
       "3   Awesome deals on Black Friday: Apps, SaaS, Boo...                567   \n",
       "4   ✯ 一个可直连访问的电视/广播图标库与相关工具项目 ✯ 🔕 永久免费 直连访问 完整开源 不...                 NA   \n",
       "5   Clash Nyanpasu!\\nLicense\\nGPL-3.0 license\\n2.2...                 26   \n",
       "6   leaked prompts of GPTs\\n2.9k stars 632 forks A...                  3   \n",
       "7   The code behind my hot tips\\n686 stars 186 for...                 NA   \n",
       "8   Focus on prompting and generating\\nLicense\\nGP...                 NA   \n",
       "9   A Collection of application ideas which can be...                 68   \n",
       "10  StarRocks, a Linux Foundation project, is a ne...                293   \n",
       "11  C Telegram bot framework\\nLicense\\nBSD-3-Claus...                 NA   \n",
       "12  🇨🇳 GitHub中文排行榜，各语言分设「软件 | 资料」榜单，精准定位中文好项目。各取所需...                 NA   \n",
       "13  🔥 🔥 🔥 现代化、开源的 Linux 服务器运维管理面板。\\n1panel.cn/\\nLi...                 38   \n",
       "14  store all agent's system prompt\\nLicense\\nMIT ...                  3   \n",
       "15  Generative Models by Stability AI\\nLicense\\nMI...                 15   \n",
       "16  A one-of-a-kind resume builder that keeps your...                 NA   \n",
       "17  12 Weeks, 24 Lessons, AI for All!\\nmicrosoft.g...                 33   \n",
       "18  A curated list of awesome C++ (or C) framework...                381   \n",
       "19  Black Friday Deals for macOS / iOS Software & ...                259   \n",
       "20  Spring Boot\\nspring.io/projects/spring-boot\\nL...              1,039   \n",
       "21  Open-source developer platform to turn scripts...                 57   \n",
       "22  Best practices for segmentation of the corpora...                 NA   \n",
       "23  真的没有QQ群、QQ频道、论坛。打包分发注意开源协议，保留出处，不守规矩就不要搞。\\nLic...                 11   \n",
       "24  Deliver web apps with confidence 🚀\\nangular.de...                 NA   \n",
       "\n",
       "   Language Used                                  Repository Title  \n",
       "0     JavaScript                   bgstaal / multipleWindow3dScene  \n",
       "1           HTML                                  run-llama / rags  \n",
       "2         Python                            teslamotors / roadster  \n",
       "3       Makefile     trungdq88 / Awesome-Black-Friday-Cyber-Monday  \n",
       "4     JavaScript                                fanmingming / live  \n",
       "5           HTML                         keiko233 / clash-nyanpasu  \n",
       "6     TypeScript                                  linexjlin / GPTs  \n",
       "7           Rust                                 wesbos / hot-tips  \n",
       "8     JavaScript                              lllyasviel / Fooocus  \n",
       "9           SCSS                           florinpop17 / app-ideas  \n",
       "10          HTML                             StarRocks / starrocks  \n",
       "11    TypeScript                                  antirez / botlib  \n",
       "12    JavaScript            GrowingGit / GitHub-Chinese-Top-Charts  \n",
       "13        Python                               1Panel-dev / 1Panel  \n",
       "14    JavaScript                LouisShark / chatgpt_system_prompt  \n",
       "15          Java                  Stability-AI / generative-models  \n",
       "16           C++                    AmruthPillai / Reactive-Resume  \n",
       "17             C                      microsoft / AI-For-Beginners  \n",
       "18        Python                             fffaraz / awesome-cpp  \n",
       "19        Thrift                         mRs- / Black-Friday-Deals  \n",
       "20         CMake                     spring-projects / spring-boot  \n",
       "21             C                          windmill-labs / windmill  \n",
       "22      Makefile  sergiomarotco / Network-segmentation-cheat-sheet  \n",
       "23          Java                       CatVodTVOfficial / TVBoxOSC  \n",
       "24            Go                                 angular / angular  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1889e47e",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the\n",
    "following details:\n",
    "    \n",
    "A) Song name\n",
    "\n",
    "B) Artist name\n",
    "\n",
    "C) Last week rank\n",
    "\n",
    "D) Peak rank\n",
    "\n",
    "E) Weeks on board\n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a59ac712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c826fddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to webdriver:\n",
    "driver=webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "\n",
    "#opening to webpage:\n",
    "url='https:/www.billboard.com/'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7220aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on HOT 100 using XPATH:\n",
    "hot_100=driver.find_element(By.XPATH,'//ul[@aria-labelledby=\"mega-menu-item-charts\"]//li[2]/a')\n",
    "try:\n",
    "    hot_100.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(hot_100.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dabef578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list for scrapping data:\n",
    "Song=[]\n",
    "Artist=[]\n",
    "Week_rank=[]\n",
    "Peak_rank=[]\n",
    "Weeks_board=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05e90405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping song\n",
    "try:\n",
    "    song=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]//ul//ul/li/h3')\n",
    "    for i in song:\n",
    "        Song.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Song.append('NA')\n",
    "\n",
    "#Scrapping artist name:\n",
    "try:\n",
    "    artists=driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li[1]/span')\n",
    "    for artist in artists:\n",
    "        Artist.append(artist.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append('NA')\n",
    "\n",
    "#Scrapping week rank:\n",
    "try:\n",
    "    week_rank=driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li[4]/span')\n",
    "    for i in week_rank:\n",
    "        Week_rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Week_rank.append('NA')\n",
    "\n",
    "#Scrapping peak rank:\n",
    "try:\n",
    "    peak_rank=driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li[5]/span')\n",
    "    for i in peak_rank:\n",
    "        Peak_rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Peak_rank.append('NA')\n",
    "\n",
    "#Scrapping week board:\n",
    "try:\n",
    "    week_board=driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li[6]/span')\n",
    "    for i in week_board:\n",
    "        Weeks_board.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Weeks_board.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42d110d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Song),len(Artist),len(Week_rank),len(Peak_rank),len(Weeks_board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f738b28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lovin On Me</td>\n",
       "      <td>Jack Harlow</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paint The Town Red</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Snooze</td>\n",
       "      <td>SZA</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is It Over Now? (Taylor's Version) [From The V...</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Mi Ex Tenia Razon</td>\n",
       "      <td>Karol G</td>\n",
       "      <td>91</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Different 'Round Here</td>\n",
       "      <td>Riley Green Featuring Luke Combs</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>But I Got A Beer In My Hand</td>\n",
       "      <td>Luke Bryan</td>\n",
       "      <td>98</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Better Than Ever</td>\n",
       "      <td>YoungBoy Never Broke Again &amp; Rod Wave</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Soak City (Do It)</td>\n",
       "      <td>310babii</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Song Name  \\\n",
       "0                                        Cruel Summer   \n",
       "1                                         Lovin On Me   \n",
       "2                                  Paint The Town Red   \n",
       "3                                              Snooze   \n",
       "4   Is It Over Now? (Taylor's Version) [From The V...   \n",
       "..                                                ...   \n",
       "95                                  Mi Ex Tenia Razon   \n",
       "96                              Different 'Round Here   \n",
       "97                        But I Got A Beer In My Hand   \n",
       "98                                   Better Than Ever   \n",
       "99                                  Soak City (Do It)   \n",
       "\n",
       "                              Artist Name Last Week Rank Peak Rank  \\\n",
       "0                            Taylor Swift              1         1   \n",
       "1                             Jack Harlow              -         2   \n",
       "2                                Doja Cat              2         1   \n",
       "3                                     SZA              4         2   \n",
       "4                            Taylor Swift              3         1   \n",
       "..                                    ...            ...       ...   \n",
       "95                                Karol G             91        22   \n",
       "96       Riley Green Featuring Luke Combs              -        97   \n",
       "97                             Luke Bryan             98        92   \n",
       "98  YoungBoy Never Broke Again & Rod Wave              -        99   \n",
       "99                               310babii              -       100   \n",
       "\n",
       "   Weeks on Board  \n",
       "0              28  \n",
       "1               1  \n",
       "2              15  \n",
       "3              49  \n",
       "4               3  \n",
       "..            ...  \n",
       "95             13  \n",
       "96              1  \n",
       "97              5  \n",
       "98              1  \n",
       "99              1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFrame for scrapped data\n",
    "Billboard=pd.DataFrame({\"Song Name\":Song,\"Artist Name\":Artist,\"Last Week Rank\":Week_rank,\"Peak Rank\":Peak_rank,\"Weeks on Board\":Weeks_board})\n",
    "Billboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25ae1fd",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of Highest selling novels.\n",
    "\n",
    "A) Book name\n",
    "\n",
    "B) Author name\n",
    "\n",
    "C) Volumes sold\n",
    "\n",
    "D) Publisher\n",
    "\n",
    "E) Genre\n",
    "\n",
    "Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c161bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d44d6a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to webdriver:\n",
    "driver=webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "\n",
    "#opening the webpage:\n",
    "url='https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c35b2d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list for scrapping data:\n",
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volume_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7200c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping Book name:\n",
    "try:\n",
    "    book_name=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "    for i in book_name:\n",
    "        Book_name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Book_name.append('NA')\n",
    "\n",
    "#Scrapping Author name:    \n",
    "try:\n",
    "    author_name=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "    for i in author_name:\n",
    "        Author_name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Author_name.append('NA')\n",
    "\n",
    "#Scrapping volume sold:    \n",
    "try:\n",
    "    volume_sold=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "    for i in volume_sold:\n",
    "        Volume_sold.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Volume_sold.append('NA')\n",
    "\n",
    "#Scrapping publisher:\n",
    "try:\n",
    "    publisher=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "    for i in publisher:\n",
    "        Publisher.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Publisher.append('NA')\n",
    "\n",
    "#Scrapping genre:\n",
    "try:\n",
    "    genre=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "    for i in genre:\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Genre.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00b9e5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Book_name),len(Author_name),len(Volume_sold),len(Publisher),len(Genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac33bf59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volume sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFrame for scapped data:\n",
    "Highest_selling_novel=pd.DataFrame({\"Book Name\":Book_name,\"Author Name\":Author_name,\"Volume sold\":Volume_sold,\"Publisher\":Publisher,\"Genre\":Genre})\n",
    "Highest_selling_novel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0d68ab",
   "metadata": {},
   "source": [
    "# 7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "\n",
    "Url = https://www.imdb.com/list/ls095964455/ \n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Year span\n",
    "\n",
    "C) Genre\n",
    "\n",
    "D) Run time\n",
    "\n",
    "E) Ratings\n",
    "\n",
    "F) Votes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b89314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7a155ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to webdriver:\n",
    "driver=webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "\n",
    "#opening to webpage\n",
    "url='https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ac18872",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty list for scrapped data\n",
    "Name=[]\n",
    "Year=[]\n",
    "Genre=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f50229d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping name:\n",
    "try:\n",
    "    name=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a')\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append('NA')\n",
    "#Scrapping year\n",
    "try:\n",
    "    year=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/span[2]')\n",
    "    for i in year:\n",
    "        Year.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Year.append('NA')\n",
    "\n",
    "#scrapping genre    \n",
    "try:\n",
    "    genre=driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"]/span[5]')\n",
    "    for i in genre:\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Genre.append('NA')\n",
    "\n",
    "#Scrapping Run time\n",
    "try:\n",
    "    run_time=driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"]/span[3]')\n",
    "    for i in run_time:\n",
    "        Run_time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Run_time.append('NA')\n",
    "\n",
    "#Scrapping Ratings\n",
    "try:\n",
    "    ratings=driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-star small\"]/span[2]')\n",
    "    for i in ratings:\n",
    "        Ratings.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Ratings.append('NA')\n",
    "\n",
    "#Scrapping votes\n",
    "try:\n",
    "    votes=driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"][3]/span[2]')\n",
    "    for i in votes:\n",
    "        Votes.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Votes.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3dfeea8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(Year),len(Genre),len(Run_time),len(Ratings),len(Votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "956394be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>4,189 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,224,779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,292,070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,055,446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>309,926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>269,048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>53,228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>65,320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>213,018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>44,355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>277,498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2025)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "     Run time Ratings      Votes  \n",
       "0   4,189 min     9.2  2,224,779  \n",
       "1      51 min     8.7  1,292,070  \n",
       "2      44 min     8.1  1,055,446  \n",
       "3      60 min     7.5    309,926  \n",
       "4      43 min     7.6    269,048  \n",
       "..        ...     ...        ...  \n",
       "95     42 min     7.5     53,228  \n",
       "96     50 min     7.8     65,320  \n",
       "97     42 min     8.1    213,018  \n",
       "98     45 min       7     44,355  \n",
       "99    572 min     8.6    277,498  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Dataframe for scrapped data\n",
    "TV_series=pd.DataFrame({\"Name\":Name,\"Year span\":Year,\"Genre\":Genre,\"Run time\":Run_time,\"Ratings\":Ratings,\"Votes\":Votes})\n",
    "TV_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95abd517",
   "metadata": {},
   "source": [
    "# 8. Details of Datasets from UCI machine learning repositories.\n",
    "\n",
    "Url = https://archive.ics.uci.edu/ \n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Dataset name\n",
    "\n",
    "B) Data type\n",
    "\n",
    "C) Task\n",
    "\n",
    "D) Attribute ty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7b3f3d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "84bf0832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conencting to webdriver\n",
    "driver=webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "\n",
    "#opening to webpage\n",
    "url='https://archive.ics.uci.edu/'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "21b6987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to dataset webpage\n",
    "dataset=driver.find_element(By.XPATH,'//div[@class=\"flex flex-wrap justify-center gap-5\"]/a[1]')\n",
    "dataset.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "436c1d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty list for scrapped data\n",
    "Dataset=[]\n",
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "Instances=[]\n",
    "Attribute=[]\n",
    "Year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "445a5b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL\n",
    "Product_URL=[]\n",
    "start=0\n",
    "end=65\n",
    "for page in range(start,end):\n",
    "    url=driver.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "    for i in url:\n",
    "        Product_URL.append(i.get_attribute('href'))\n",
    "    nxt_button=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[3]/div/button[2]')\n",
    "    nxt_button.click()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b73ce292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Product_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "37fae3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Product_URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Scrapping dataset\n",
    "    try:\n",
    "        dataset=driver.find_elements(By.XPATH,'//div[@class=\"flex flex-col\"]//div[1]//div[2]//div[1]//h1')\n",
    "        for i in dataset:\n",
    "            Dataset.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Dataset.append('NA')\n",
    "    \n",
    "    #Scrapping type\n",
    "    try:\n",
    "        Type=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[1]/p')\n",
    "        Data_type.append(Type.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_type.append('NA')\n",
    "    \n",
    "# Scraping Task via Xpath\n",
    "    try:\n",
    "        task=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[3]/p')\n",
    "        Task.append(task.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append('NA')\n",
    "    \n",
    "    #Scrapping attribute\n",
    "    try:\n",
    "        attribute=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[4]/p')\n",
    "        Attribute_type.append(attribute.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute_type.append('NA')\n",
    "        \n",
    "        \n",
    "# Scraping No_of_Instances via Xpath\n",
    "    try:\n",
    "        no_of_Instances=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[5]/p')\n",
    "        Instances.append(no_of_Instances.text)\n",
    "    except NoSuchElementException:\n",
    "        Instances.append('NA')\n",
    "\n",
    "# Scraping No_of_Attribute via Xpath\n",
    "    try:\n",
    "        no_of_Attribute=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[6]/p')\n",
    "        Attribute.append(no_of_Attribute.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute.append('NA')\n",
    "    \n",
    "# Scraping Year via Xpath\n",
    "    try:\n",
    "        year=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[1]/div[2]/h2')\n",
    "        Year.append(year.text)\n",
    "    except NoSuchElementException:\n",
    "        Year.append('NA')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4cdac5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649 650 650 650 650 650 650\n"
     ]
    }
   ],
   "source": [
    "print(len(Dataset),len(Data_type),len(Task),len(Attribute_type),len(Instances),len(Attribute),len(Year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2bc3fa31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Data</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attributes_type</th>\n",
       "      <th>Instances</th>\n",
       "      <th>Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>Donated on 6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>13</td>\n",
       "      <td>Donated on 6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>Donated on 4/30/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178</td>\n",
       "      <td>13</td>\n",
       "      <td>Donated on 6/30/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>30</td>\n",
       "      <td>Donated on 10/31/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>Qualitative Structure Activity Relationships</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>-</td>\n",
       "      <td>Categorical, Real</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Donated on 1/27/1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>TTC-3600: Benchmark dataset for Turkish text c...</td>\n",
       "      <td>Domain-Theory</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>Logic Theorist</td>\n",
       "      <td>Text</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer</td>\n",
       "      <td>3600</td>\n",
       "      <td>4814</td>\n",
       "      <td>Donated on 2/7/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>University of Tehran Question Dataset 2016 (UT...</td>\n",
       "      <td>Domain-Theory</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>USPTO Algorithm Challenge, run by NASA-Harvard...</td>\n",
       "      <td>Text</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>1175</td>\n",
       "      <td>3</td>\n",
       "      <td>Donated on 9/26/2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Dataset  \\\n",
       "0                                                 Iris   \n",
       "1                                        Heart Disease   \n",
       "2                                                Adult   \n",
       "3                                                 Wine   \n",
       "4                 Breast Cancer Wisconsin (Diagnostic)   \n",
       "..                                                 ...   \n",
       "635       Qualitative Structure Activity Relationships   \n",
       "636  TTC-3600: Benchmark dataset for Turkish text c...   \n",
       "637                                     Logic Theorist   \n",
       "638  University of Tehran Question Dataset 2016 (UT...   \n",
       "639  USPTO Algorithm Challenge, run by NASA-Harvard...   \n",
       "\n",
       "                          Data                        Task  \\\n",
       "0                      Tabular              Classification   \n",
       "1                 Multivariate              Classification   \n",
       "2                 Multivariate              Classification   \n",
       "3                      Tabular              Classification   \n",
       "4                 Multivariate              Classification   \n",
       "..                         ...                         ...   \n",
       "635  Multivariate, Time-Series                           -   \n",
       "636              Domain-Theory                           -   \n",
       "637                       Text  Classification, Clustering   \n",
       "638              Domain-Theory                           -   \n",
       "639                       Text              Classification   \n",
       "\n",
       "                Attributes_type Instances Attributes                   Year  \n",
       "0                          Real       150          4   Donated on 6/30/1988  \n",
       "1    Categorical, Integer, Real       303         13   Donated on 6/30/1988  \n",
       "2          Categorical, Integer     48842         14   Donated on 4/30/1996  \n",
       "3                 Integer, Real       178         13   Donated on 6/30/1991  \n",
       "4                          Real       569         30  Donated on 10/31/1995  \n",
       "..                          ...       ...        ...                    ...  \n",
       "635           Categorical, Real         -          -   Donated on 1/27/1999  \n",
       "636                           -         -          -                     NA  \n",
       "637                     Integer      3600       4814    Donated on 2/7/2017  \n",
       "638                           -         -          -                     NA  \n",
       "639                           -      1175          3   Donated on 9/26/2017  \n",
       "\n",
       "[640 rows x 7 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset=pd.DataFrame({\"Dataset\":Dataset[:640],\"Data\":Data_type[:640],\"Task\":Task[:640],\"Attributes_type\":Attribute_type[:640],\"Instances\":Instances[:640],\"Attributes\":Attribute[:640],\"Year\":Year[:640]})\n",
    "Dataset                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a1816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
